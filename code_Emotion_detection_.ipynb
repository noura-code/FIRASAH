{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "code Emotion detection .ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rpAhvvZDEhY8",
        "outputId": "76a50b8c-26d9-4691-c05d-1dd4fa94c1b1"
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from random import shuffle\n",
        "from tqdm import tqdm\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "#import path\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Dropout,Flatten,Conv2D,MaxPooling2D\n",
        "import zipfile\n",
        "from google.colab import drive\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils.np_utils import to_categorical\n",
        "drive.mount('/content/drive/')\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/dataset job13-2.zip\", 'r')\n",
        "zip_ref.extractall(\"/content/\")\n",
        "zip_ref.close()\n",
        "training_dir = \"train\"\n",
        "testing_dir = \"test\"\n",
        "Y = []\n",
        "t_angry = [\"/content/dataset job13-2/train/angry\".format(i) for i in os.listdir(\"/content/dataset job13-2/train/angry\")]\n",
        "for im in t_angry:\n",
        "    Y.append(0)\n",
        "t_disgust = [\"/content/dataset job13-2/train/disgust/{}\".format(i) for i in os.listdir(\"/content/dataset job13-2/train/disgust/\")]\n",
        "for im in t_disgust:\n",
        "    Y.append(1)\n",
        "t_fear = [\"/content/dataset job13-2/train/fear/{}\".format(i) for i in os.listdir(\"/content/dataset job13-2/train/fear/\")]\n",
        "for im in t_fear:\n",
        "    Y.append(2)\n",
        "t_happy = [\"/content/dataset job13-2/train/happy/{}\".format(i) for i in os.listdir(\"/content/dataset job13-2/train/happy/\")]\n",
        "for im in t_happy:\n",
        "    Y.append(3)\n",
        "t_neutral = [\"/content/dataset job13-2/train/neutral/{}\".format(i) for i in os.listdir(\"/content/dataset job13-2/train/neutral/\")]\n",
        "for im in t_neutral:\n",
        "    Y.append(4)\n",
        "t_sad= [\"/content/dataset job13-2/train/sad/{}\".format(i) for i in os.listdir(\"/content/dataset job13-2/train/sad/\")]\n",
        "for im in t_sad:\n",
        "    Y.append(5)\n",
        "t_surprise= [\"/content/dataset job13-2/train/surprise/{}\".format(i) for i in os.listdir(\"/content/dataset job13-2/train/surprise/\")]\n",
        "for im in t_surprise:\n",
        "    Y.append(6)\n",
        "train_imgs = t_angry + t_disgust + t_fear + t_happy + t_neutral + t_sad + t_surprise\n",
        "#test_imgs = [\"/content/test/\"+f+\"/\"+i for f in os.listdir(\"test\") for i in os.listdir(\"test/\"+f)]\n",
        "random.shuffle(train_imgs)\n",
        "nrows = 48\n",
        "ncolumns = 48\n",
        "ch = 3\n",
        "X = []\n",
        "for im in tqdm(train_imgs):\n",
        "    X.append(cv2.imread(im))\n",
        "x_train,x_val,y_train,y_val = train_test_split(X,Y,test_size=0.1,random_state=2)\n",
        "\n",
        "train_datagen = ImageDataGenerator()\n",
        "test_datagen = ImageDataGenerator()\n",
        "train_generator = train_datagen.flow_from_directory(\"/content/dataset job13-2/train\",\n",
        "                                                    batch_size=128,\n",
        "                                                    color_mode=\"grayscale\",\n",
        "                                                    class_mode=\"categorical\",\n",
        "                                                    target_size=(48,48),\n",
        "                                                    shuffle=True)\n",
        "test_generator = test_datagen.flow_from_directory(\"/content/dataset job13-2/test\",\n",
        "                                                  batch_size=128,\n",
        "                                                    color_mode=\"grayscale\",\n",
        "                                                    class_mode=\"categorical\",\n",
        "                                                    target_size=(48,48),\n",
        "                                                    shuffle=False)\n",
        "model = Sequential()\n",
        "model.add(Conv2D(input_shape=(48,48,1),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(1024,activation=\"relu\"))\n",
        "model.add(Dense(2048,activation=\"relu\"))\n",
        "model.add(Dropout(0.50))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(4096,activation=\"relu\"))\n",
        "model.add(Dense(4096,activation=\"relu\"))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(7,activation=\"softmax\"))\n",
        "adam = Adam(lr=0.0001)\n",
        "\n",
        "model.compile(optimizer=adam,loss=\"categorical_crossentropy\",metrics = ['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "x_train = np.array(x_train)\n",
        "y_train = np.array(y_train)\n",
        "x_val = np.array(x_val)\n",
        "y_val = np.array(y_val)\n",
        "y_train= to_categorical(y_train, num_classes=7)\n",
        "y_val = to_categorical(y_val, num_classes=7)\n",
        "history = model.fit_generator(generator=train_generator,epochs=100,validation_data=test_generator,\n",
        "                              steps_per_epoch=train_generator.n//train_generator.batch_size,\n",
        "                              validation_steps=test_generator.n//test_generator.batch_size)\n",
        "model.save(\"model.exp\")\n",
        "plt.plot(history.history[\"accuracy\"])\n",
        "plt.plot(history.history[\"val_accuracy\"])\n",
        "plt.title(\"model accuracy\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.legend([\"train\",\"validation\"],loc=\"upper left\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 29642/29642 [00:01<00:00, 18128.97it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 29636 images belonging to 7 classes.\n",
            "Found 7178 images belonging to 7 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:111: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:113: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1915: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_29 (Conv2D)           (None, 48, 48, 64)        640       \n",
            "_________________________________________________________________\n",
            "conv2d_30 (Conv2D)           (None, 48, 48, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_31 (Conv2D)           (None, 24, 24, 128)       73856     \n",
            "_________________________________________________________________\n",
            "conv2d_32 (Conv2D)           (None, 24, 24, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_33 (Conv2D)           (None, 12, 12, 256)       295168    \n",
            "_________________________________________________________________\n",
            "conv2d_34 (Conv2D)           (None, 12, 12, 256)       590080    \n",
            "_________________________________________________________________\n",
            "conv2d_35 (Conv2D)           (None, 12, 12, 256)       590080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_36 (Conv2D)           (None, 6, 6, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "conv2d_37 (Conv2D)           (None, 6, 6, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_38 (Conv2D)           (None, 6, 6, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 3, 3, 512)         0         \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 3, 3, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_39 (Conv2D)           (None, 3, 3, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_40 (Conv2D)           (None, 3, 3, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_41 (Conv2D)           (None, 3, 3, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 1, 1, 1024)        525312    \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1, 1, 2048)        2099200   \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 1, 1, 2048)        0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 4096)              8392704   \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 7)                 28679     \n",
            "=================================================================\n",
            "Total params: 42,540,743\n",
            "Trainable params: 42,540,743\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "231/231 [==============================] - 20s 78ms/step - loss: 1.8404 - accuracy: 0.2514 - val_loss: 1.8177 - val_accuracy: 0.2475\n",
            "Epoch 2/100\n",
            "231/231 [==============================] - 17s 74ms/step - loss: 1.8149 - accuracy: 0.2538 - val_loss: 1.6268 - val_accuracy: 0.3488\n",
            "Epoch 3/100\n",
            "231/231 [==============================] - 17s 75ms/step - loss: 1.6103 - accuracy: 0.3549 - val_loss: 1.4694 - val_accuracy: 0.4159\n",
            "Epoch 4/100\n",
            "231/231 [==============================] - 17s 74ms/step - loss: 1.4527 - accuracy: 0.4239 - val_loss: 1.3918 - val_accuracy: 0.4583\n",
            "Epoch 5/100\n",
            "231/231 [==============================] - 17s 74ms/step - loss: 1.3618 - accuracy: 0.4664 - val_loss: 1.3038 - val_accuracy: 0.4863\n",
            "Epoch 6/100\n",
            "231/231 [==============================] - 17s 74ms/step - loss: 1.3033 - accuracy: 0.4921 - val_loss: 1.2411 - val_accuracy: 0.5162\n",
            "Epoch 7/100\n",
            "231/231 [==============================] - 17s 74ms/step - loss: 1.2273 - accuracy: 0.5247 - val_loss: 1.2034 - val_accuracy: 0.5319\n",
            "Epoch 8/100\n",
            "231/231 [==============================] - 17s 74ms/step - loss: 1.1748 - accuracy: 0.5496 - val_loss: 1.1928 - val_accuracy: 0.5472\n",
            "Epoch 9/100\n",
            "231/231 [==============================] - 17s 74ms/step - loss: 1.1371 - accuracy: 0.5647 - val_loss: 1.1933 - val_accuracy: 0.5453\n",
            "Epoch 10/100\n",
            "231/231 [==============================] - 17s 74ms/step - loss: 1.0787 - accuracy: 0.5907 - val_loss: 1.1217 - val_accuracy: 0.5612\n",
            "Epoch 11/100\n",
            "231/231 [==============================] - 17s 74ms/step - loss: 1.0333 - accuracy: 0.6054 - val_loss: 1.1089 - val_accuracy: 0.5771\n",
            "Epoch 12/100\n",
            "231/231 [==============================] - 17s 74ms/step - loss: 1.0034 - accuracy: 0.6205 - val_loss: 1.1124 - val_accuracy: 0.5699\n",
            "Epoch 13/100\n",
            "231/231 [==============================] - 17s 74ms/step - loss: 0.9514 - accuracy: 0.6423 - val_loss: 1.1102 - val_accuracy: 0.5858\n",
            "Epoch 14/100\n",
            "231/231 [==============================] - 17s 74ms/step - loss: 0.9030 - accuracy: 0.6587 - val_loss: 1.1028 - val_accuracy: 0.5918\n",
            "Epoch 15/100\n",
            "231/231 [==============================] - 17s 74ms/step - loss: 0.8549 - accuracy: 0.6849 - val_loss: 1.1037 - val_accuracy: 0.5942\n",
            "Epoch 16/100\n",
            "231/231 [==============================] - 17s 74ms/step - loss: 0.7972 - accuracy: 0.7074 - val_loss: 1.0942 - val_accuracy: 0.6064\n",
            "Epoch 17/100\n",
            "231/231 [==============================] - 17s 74ms/step - loss: 0.7479 - accuracy: 0.7250 - val_loss: 1.1128 - val_accuracy: 0.6147\n",
            "Epoch 18/100\n",
            "231/231 [==============================] - 17s 74ms/step - loss: 0.6985 - accuracy: 0.7445 - val_loss: 1.1531 - val_accuracy: 0.6137\n",
            "Epoch 19/100\n",
            "231/231 [==============================] - 17s 74ms/step - loss: 0.6390 - accuracy: 0.7686 - val_loss: 1.1218 - val_accuracy: 0.6161\n",
            "Epoch 20/100\n",
            "231/231 [==============================] - 17s 74ms/step - loss: 0.6008 - accuracy: 0.7829 - val_loss: 1.1768 - val_accuracy: 0.6158\n",
            "Epoch 21/100\n",
            "231/231 [==============================] - 17s 75ms/step - loss: 0.5495 - accuracy: 0.7992 - val_loss: 1.2357 - val_accuracy: 0.6205\n",
            "Epoch 22/100\n",
            "231/231 [==============================] - 17s 74ms/step - loss: 0.5020 - accuracy: 0.8166 - val_loss: 1.2471 - val_accuracy: 0.6182\n",
            "Epoch 23/100\n",
            "231/231 [==============================] - 17s 74ms/step - loss: 0.4670 - accuracy: 0.8312 - val_loss: 1.2990 - val_accuracy: 0.6268\n",
            "Epoch 24/100\n",
            "231/231 [==============================] - 17s 75ms/step - loss: 0.4055 - accuracy: 0.8552 - val_loss: 1.3736 - val_accuracy: 0.6078\n",
            "Epoch 25/100\n",
            "231/231 [==============================] - 17s 74ms/step - loss: 0.3823 - accuracy: 0.8632 - val_loss: 1.3906 - val_accuracy: 0.6219\n",
            "Epoch 26/100\n",
            "231/231 [==============================] - 17s 74ms/step - loss: 0.3451 - accuracy: 0.8782 - val_loss: 1.4473 - val_accuracy: 0.6207\n",
            "Epoch 27/100\n",
            "231/231 [==============================] - 17s 75ms/step - loss: 0.3287 - accuracy: 0.8877 - val_loss: 1.4838 - val_accuracy: 0.6215\n",
            "Epoch 28/100\n",
            "231/231 [==============================] - 17s 76ms/step - loss: 0.2903 - accuracy: 0.8997 - val_loss: 1.4910 - val_accuracy: 0.6144\n",
            "Epoch 29/100\n",
            "231/231 [==============================] - 17s 75ms/step - loss: 0.2793 - accuracy: 0.9022 - val_loss: 1.5926 - val_accuracy: 0.6222\n",
            "Epoch 30/100\n",
            "231/231 [==============================] - 17s 74ms/step - loss: 0.2434 - accuracy: 0.9158 - val_loss: 1.5502 - val_accuracy: 0.6251\n",
            "Epoch 31/100\n",
            "231/231 [==============================] - 17s 75ms/step - loss: 0.2283 - accuracy: 0.9204 - val_loss: 1.6604 - val_accuracy: 0.6268\n",
            "Epoch 32/100\n",
            "231/231 [==============================] - 17s 74ms/step - loss: 0.2126 - accuracy: 0.9252 - val_loss: 1.7444 - val_accuracy: 0.6223\n",
            "Epoch 33/100\n",
            "231/231 [==============================] - 18s 76ms/step - loss: 0.2038 - accuracy: 0.9302 - val_loss: 1.8134 - val_accuracy: 0.6230\n",
            "Epoch 34/100\n",
            "231/231 [==============================] - 17s 75ms/step - loss: 0.1945 - accuracy: 0.9296 - val_loss: 1.8316 - val_accuracy: 0.6194\n",
            "Epoch 35/100\n",
            "231/231 [==============================] - 17s 75ms/step - loss: 0.1800 - accuracy: 0.9365 - val_loss: 1.7738 - val_accuracy: 0.6205\n",
            "Epoch 36/100\n",
            "231/231 [==============================] - 17s 75ms/step - loss: 0.1786 - accuracy: 0.9398 - val_loss: 1.8540 - val_accuracy: 0.6175\n",
            "Epoch 37/100\n",
            "231/231 [==============================] - 17s 75ms/step - loss: 0.1602 - accuracy: 0.9447 - val_loss: 1.7151 - val_accuracy: 0.6197\n",
            "Epoch 38/100\n",
            "231/231 [==============================] - 17s 75ms/step - loss: 0.1527 - accuracy: 0.9478 - val_loss: 1.7634 - val_accuracy: 0.6203\n",
            "Epoch 39/100\n",
            "231/231 [==============================] - 17s 75ms/step - loss: 0.1430 - accuracy: 0.9533 - val_loss: 1.7705 - val_accuracy: 0.6183\n",
            "Epoch 40/100\n",
            "231/231 [==============================] - 17s 75ms/step - loss: 0.1381 - accuracy: 0.9529 - val_loss: 1.7590 - val_accuracy: 0.6208\n",
            "Epoch 41/100\n",
            "231/231 [==============================] - 17s 75ms/step - loss: 0.1336 - accuracy: 0.9556 - val_loss: 1.9296 - val_accuracy: 0.6279\n",
            "Epoch 42/100\n",
            "231/231 [==============================] - 17s 75ms/step - loss: 0.1301 - accuracy: 0.9552 - val_loss: 1.7507 - val_accuracy: 0.6240\n",
            "Epoch 43/100\n",
            "231/231 [==============================] - 17s 75ms/step - loss: 0.1242 - accuracy: 0.9580 - val_loss: 1.9945 - val_accuracy: 0.6223\n",
            "Epoch 44/100\n",
            "231/231 [==============================] - 17s 76ms/step - loss: 0.1253 - accuracy: 0.9561 - val_loss: 1.9183 - val_accuracy: 0.6265\n",
            "Epoch 45/100\n",
            "231/231 [==============================] - 17s 75ms/step - loss: 0.1151 - accuracy: 0.9592 - val_loss: 2.0000 - val_accuracy: 0.6219\n",
            "Epoch 46/100\n",
            "231/231 [==============================] - 17s 75ms/step - loss: 0.1098 - accuracy: 0.9631 - val_loss: 2.0329 - val_accuracy: 0.6285\n",
            "Epoch 47/100\n",
            "231/231 [==============================] - 17s 75ms/step - loss: 0.1161 - accuracy: 0.9596 - val_loss: 1.9042 - val_accuracy: 0.6201\n",
            "Epoch 48/100\n",
            "231/231 [==============================] - 18s 76ms/step - loss: 0.1074 - accuracy: 0.9644 - val_loss: 2.0594 - val_accuracy: 0.6278\n",
            "Epoch 49/100\n",
            "231/231 [==============================] - 17s 76ms/step - loss: 0.1113 - accuracy: 0.9634 - val_loss: 1.9400 - val_accuracy: 0.6293\n",
            "Epoch 50/100\n",
            "231/231 [==============================] - 18s 76ms/step - loss: 0.1026 - accuracy: 0.9651 - val_loss: 2.0436 - val_accuracy: 0.6249\n",
            "Epoch 51/100\n",
            "231/231 [==============================] - 17s 75ms/step - loss: 0.0957 - accuracy: 0.9663 - val_loss: 1.9422 - val_accuracy: 0.6164\n",
            "Epoch 52/100\n",
            "231/231 [==============================] - 18s 76ms/step - loss: 0.0911 - accuracy: 0.9703 - val_loss: 1.8383 - val_accuracy: 0.6235\n",
            "Epoch 53/100\n",
            "231/231 [==============================] - 17s 75ms/step - loss: 0.0960 - accuracy: 0.9667 - val_loss: 2.1320 - val_accuracy: 0.6189\n",
            "Epoch 54/100\n",
            "231/231 [==============================] - 17s 75ms/step - loss: 0.0918 - accuracy: 0.9702 - val_loss: 2.0040 - val_accuracy: 0.6182\n",
            "Epoch 55/100\n",
            "231/231 [==============================] - 17s 75ms/step - loss: 0.0874 - accuracy: 0.9698 - val_loss: 2.0375 - val_accuracy: 0.6221\n",
            "Epoch 56/100\n",
            "231/231 [==============================] - 17s 75ms/step - loss: 0.0828 - accuracy: 0.9717 - val_loss: 2.0480 - val_accuracy: 0.6247\n",
            "Epoch 57/100\n",
            "231/231 [==============================] - 17s 75ms/step - loss: 0.0915 - accuracy: 0.9679 - val_loss: 2.1107 - val_accuracy: 0.6210\n",
            "Epoch 58/100\n",
            "231/231 [==============================] - 17s 75ms/step - loss: 0.0767 - accuracy: 0.9735 - val_loss: 2.0971 - val_accuracy: 0.6235\n",
            "Epoch 59/100\n",
            "231/231 [==============================] - 17s 75ms/step - loss: 0.0798 - accuracy: 0.9730 - val_loss: 2.2236 - val_accuracy: 0.6239\n",
            "Epoch 60/100\n",
            "231/231 [==============================] - 18s 76ms/step - loss: 0.0785 - accuracy: 0.9736 - val_loss: 2.0957 - val_accuracy: 0.6293\n",
            "Epoch 61/100\n",
            "231/231 [==============================] - 17s 74ms/step - loss: 0.0764 - accuracy: 0.9738 - val_loss: 2.0673 - val_accuracy: 0.6235\n",
            "Epoch 62/100\n",
            "231/231 [==============================] - 17s 75ms/step - loss: 0.0797 - accuracy: 0.9743 - val_loss: 2.2717 - val_accuracy: 0.6152\n",
            "Epoch 63/100\n",
            "231/231 [==============================] - 17s 75ms/step - loss: 0.0765 - accuracy: 0.9750 - val_loss: 1.9857 - val_accuracy: 0.6302\n",
            "Epoch 64/100\n",
            "231/231 [==============================] - 17s 75ms/step - loss: 0.0772 - accuracy: 0.9736 - val_loss: 2.0151 - val_accuracy: 0.6237\n",
            "Epoch 65/100\n",
            "231/231 [==============================] - 17s 74ms/step - loss: 0.0668 - accuracy: 0.9769 - val_loss: 2.2224 - val_accuracy: 0.6246\n",
            "Epoch 66/100\n",
            "231/231 [==============================] - 17s 74ms/step - loss: 0.0756 - accuracy: 0.9742 - val_loss: 2.3273 - val_accuracy: 0.6299\n",
            "Epoch 67/100\n",
            "231/231 [==============================] - 17s 76ms/step - loss: 0.0831 - accuracy: 0.9729 - val_loss: 2.1651 - val_accuracy: 0.6221\n",
            "Epoch 68/100\n",
            "231/231 [==============================] - 17s 74ms/step - loss: 0.0735 - accuracy: 0.9746 - val_loss: 2.2199 - val_accuracy: 0.6281\n",
            "Epoch 69/100\n",
            "231/231 [==============================] - 17s 74ms/step - loss: 0.0775 - accuracy: 0.9737 - val_loss: 2.1573 - val_accuracy: 0.6204\n",
            "Epoch 70/100\n",
            "231/231 [==============================] - 17s 75ms/step - loss: 0.0668 - accuracy: 0.9768 - val_loss: 2.2969 - val_accuracy: 0.6274\n",
            "Epoch 71/100\n",
            "231/231 [==============================] - 17s 75ms/step - loss: 0.0676 - accuracy: 0.9764 - val_loss: 2.2437 - val_accuracy: 0.6257\n",
            "Epoch 72/100\n",
            "231/231 [==============================] - 17s 75ms/step - loss: 0.0647 - accuracy: 0.9786 - val_loss: 2.2226 - val_accuracy: 0.6162\n",
            "Epoch 73/100\n",
            "231/231 [==============================] - 17s 74ms/step - loss: 0.0640 - accuracy: 0.9779 - val_loss: 2.1824 - val_accuracy: 0.6292\n",
            "Epoch 74/100\n",
            "231/231 [==============================] - 17s 75ms/step - loss: 0.0746 - accuracy: 0.9750 - val_loss: 2.1132 - val_accuracy: 0.6292\n",
            "Epoch 75/100\n",
            "231/231 [==============================] - 17s 75ms/step - loss: 0.0612 - accuracy: 0.9805 - val_loss: 2.2411 - val_accuracy: 0.6249\n",
            "Epoch 76/100\n",
            "231/231 [==============================] - 17s 75ms/step - loss: 0.0660 - accuracy: 0.9769 - val_loss: 2.2255 - val_accuracy: 0.6350\n",
            "Epoch 77/100\n",
            "231/231 [==============================] - 17s 75ms/step - loss: 0.0600 - accuracy: 0.9793 - val_loss: 2.2101 - val_accuracy: 0.6263\n",
            "Epoch 78/100\n",
            "231/231 [==============================] - 17s 75ms/step - loss: 0.0638 - accuracy: 0.9789 - val_loss: 2.2153 - val_accuracy: 0.6297\n",
            "Epoch 79/100\n",
            "231/231 [==============================] - 17s 76ms/step - loss: 0.0607 - accuracy: 0.9795 - val_loss: 2.3406 - val_accuracy: 0.6285\n",
            "Epoch 80/100\n",
            "231/231 [==============================] - 17s 75ms/step - loss: 0.0611 - accuracy: 0.9797 - val_loss: 2.5248 - val_accuracy: 0.6140\n",
            "Epoch 81/100\n",
            "231/231 [==============================] - 17s 75ms/step - loss: 0.0661 - accuracy: 0.9773 - val_loss: 2.3486 - val_accuracy: 0.6254\n",
            "Epoch 82/100\n",
            "231/231 [==============================] - 17s 75ms/step - loss: 0.0619 - accuracy: 0.9788 - val_loss: 2.3154 - val_accuracy: 0.6268\n",
            "Epoch 83/100\n",
            "231/231 [==============================] - 17s 75ms/step - loss: 0.0625 - accuracy: 0.9790 - val_loss: 2.2282 - val_accuracy: 0.6324\n",
            "Epoch 84/100\n",
            "231/231 [==============================] - 17s 74ms/step - loss: 0.0546 - accuracy: 0.9813 - val_loss: 2.3503 - val_accuracy: 0.6222\n",
            "Epoch 85/100\n",
            "231/231 [==============================] - 17s 75ms/step - loss: 0.0618 - accuracy: 0.9787 - val_loss: 2.1808 - val_accuracy: 0.6334\n",
            "Epoch 86/100\n",
            "231/231 [==============================] - 17s 75ms/step - loss: 0.0559 - accuracy: 0.9819 - val_loss: 2.3473 - val_accuracy: 0.6362\n",
            "Epoch 87/100\n",
            "231/231 [==============================] - 17s 75ms/step - loss: 0.0571 - accuracy: 0.9815 - val_loss: 2.1694 - val_accuracy: 0.6258\n",
            "Epoch 88/100\n",
            "231/231 [==============================] - 17s 75ms/step - loss: 0.0506 - accuracy: 0.9830 - val_loss: 2.0495 - val_accuracy: 0.6190\n",
            "Epoch 89/100\n",
            "231/231 [==============================] - 17s 75ms/step - loss: 0.0594 - accuracy: 0.9806 - val_loss: 2.4464 - val_accuracy: 0.6232\n",
            "Epoch 90/100\n",
            "231/231 [==============================] - 17s 75ms/step - loss: 0.0604 - accuracy: 0.9793 - val_loss: 2.5073 - val_accuracy: 0.6317\n",
            "Epoch 91/100\n",
            "231/231 [==============================] - 17s 76ms/step - loss: 0.0554 - accuracy: 0.9811 - val_loss: 2.3520 - val_accuracy: 0.6236\n",
            "Epoch 92/100\n",
            "231/231 [==============================] - 17s 74ms/step - loss: 0.0556 - accuracy: 0.9818 - val_loss: 2.4527 - val_accuracy: 0.6243\n",
            "Epoch 93/100\n",
            "231/231 [==============================] - 17s 75ms/step - loss: 0.0551 - accuracy: 0.9818 - val_loss: 2.4799 - val_accuracy: 0.6289\n",
            "Epoch 94/100\n",
            "231/231 [==============================] - 17s 75ms/step - loss: 0.0612 - accuracy: 0.9788 - val_loss: 2.4120 - val_accuracy: 0.6237\n",
            "Epoch 95/100\n",
            "231/231 [==============================] - 17s 75ms/step - loss: 0.0521 - accuracy: 0.9827 - val_loss: 2.6227 - val_accuracy: 0.6235\n",
            "Epoch 96/100\n",
            "231/231 [==============================] - 17s 75ms/step - loss: 0.0433 - accuracy: 0.9840 - val_loss: 2.1176 - val_accuracy: 0.6256\n",
            "Epoch 97/100\n",
            "231/231 [==============================] - 17s 75ms/step - loss: 0.0502 - accuracy: 0.9829 - val_loss: 2.2858 - val_accuracy: 0.6232\n",
            "Epoch 98/100\n",
            "231/231 [==============================] - 17s 75ms/step - loss: 0.0491 - accuracy: 0.9832 - val_loss: 2.5005 - val_accuracy: 0.6275\n",
            "Epoch 99/100\n",
            "231/231 [==============================] - 17s 74ms/step - loss: 0.0495 - accuracy: 0.9831 - val_loss: 2.1768 - val_accuracy: 0.6373\n",
            "Epoch 100/100\n",
            "231/231 [==============================] - 17s 75ms/step - loss: 0.0504 - accuracy: 0.9835 - val_loss: 2.1943 - val_accuracy: 0.6311\n",
            "INFO:tensorflow:Assets written to: model.exp/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3feD8-MoBn1",
        "outputId": "f27980a1-6c98-4abb-d4e3-5c6a7ffbd077"
      },
      "source": [
        "model.load_weights('model.exp')\n",
        "\n",
        "predicted_classes = model.predict_classes(test_generator)\n",
        "\n",
        "class_indices = train_generator.class_indices\n",
        "class_indices = dict((v,k) for k,v in class_indices.items())\n",
        "true_classes = test_generator.classes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5TAshCenZcG"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "\n",
        "def display_results(y_true, y_preds, class_labels):\n",
        "    \n",
        "    results = pd.DataFrame(precision_recall_fscore_support(y_true, y_preds),\n",
        "                          columns=class_labels).T\n",
        "\n",
        "    results.rename(columns={0: 'Precision', 1: 'Recall',\n",
        "                            2: 'F-Score', 3: 'Support'}, inplace=True)\n",
        "    \n",
        "    results.sort_values(by='F-Score', ascending=False, inplace=True)                           \n",
        "    global_acc = accuracy_score(y_true, y_preds)\n",
        "    \n",
        "    print(\"Overall Categorical Accuracy: {:.2f}%\".format(global_acc*100))\n",
        "    return results\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "RqKoqNZanl6N",
        "outputId": "4443b7d4-825c-4b91-c7f1-83bcf54c7582"
      },
      "source": [
        "display_results(true_classes, predicted_classes, class_indices.values())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overall Categorical Accuracy: 62.79%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F-Score</th>\n",
              "      <th>Support</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>happy</th>\n",
              "      <td>0.836142</td>\n",
              "      <td>0.811161</td>\n",
              "      <td>0.823462</td>\n",
              "      <td>1774.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>surprise</th>\n",
              "      <td>0.785714</td>\n",
              "      <td>0.767750</td>\n",
              "      <td>0.776628</td>\n",
              "      <td>831.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>disgust</th>\n",
              "      <td>0.784810</td>\n",
              "      <td>0.558559</td>\n",
              "      <td>0.652632</td>\n",
              "      <td>111.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>neutral</th>\n",
              "      <td>0.558824</td>\n",
              "      <td>0.570154</td>\n",
              "      <td>0.564432</td>\n",
              "      <td>1233.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>angry</th>\n",
              "      <td>0.544385</td>\n",
              "      <td>0.531315</td>\n",
              "      <td>0.537771</td>\n",
              "      <td>958.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sad</th>\n",
              "      <td>0.471826</td>\n",
              "      <td>0.557338</td>\n",
              "      <td>0.511029</td>\n",
              "      <td>1247.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fear</th>\n",
              "      <td>0.512222</td>\n",
              "      <td>0.450195</td>\n",
              "      <td>0.479210</td>\n",
              "      <td>1024.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Precision    Recall   F-Score  Support\n",
              "happy      0.836142  0.811161  0.823462   1774.0\n",
              "surprise   0.785714  0.767750  0.776628    831.0\n",
              "disgust    0.784810  0.558559  0.652632    111.0\n",
              "neutral    0.558824  0.570154  0.564432   1233.0\n",
              "angry      0.544385  0.531315  0.537771    958.0\n",
              "sad        0.471826  0.557338  0.511029   1247.0\n",
              "fear       0.512222  0.450195  0.479210   1024.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "_y-xMvknCnzS",
        "outputId": "d5ba9882-ac22-471d-bf17-88881ba66d3c"
      },
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import os\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from os import path\n",
        "from keras.models import load_model\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "from base64 import b64encode\n",
        "import cv2\n",
        "import PIL\n",
        "import io\n",
        "import html\n",
        "import time\n",
        "if path.exists(\"res\") == False:\n",
        "  os.mkdir(\"res\")\n",
        "  os.mkdir(\"res/angry\")\n",
        "  os.mkdir(\"res/fear\")\n",
        "  os.mkdir(\"res/neutral\")\n",
        "model = load_model(\"model.exp\")\n",
        "labels = [\"angry\",\"disgust\",\"fear\",\"happy\",\"neutral\",\"sad\",\"surprise\"]\n",
        "def js_to_image(js_res):\n",
        "  image_bytes = b64decode(js_res.split(\",\")[1])\n",
        "  jpg_as_np = np.frombuffer(image_bytes,dtype=np.int8)\n",
        "  img = cv2.imdecode(jpg_as_np,flags=1)\n",
        "  return img\n",
        "# initialize the Haar Cascade face detection model\n",
        "face_cascade = cv2.CascadeClassifier(cv2.samples.findFile(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'))\n",
        "def bbox_to_bytes(bbox_array):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          bbox_array: Numpy array (pixels) containing rectangle to overlay on video stream.\n",
        "  Returns:\n",
        "        bytes: Base64 image byte string\n",
        "  \"\"\"\n",
        "  # convert array into PIL image\n",
        "  bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n",
        "  iobuf = io.BytesIO()\n",
        "  # format bbox into png for return\n",
        "  bbox_PIL.save(iobuf, format='png')\n",
        "  # format return string\n",
        "  bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n",
        "\n",
        "  return bbox_bytes\n",
        "# JavaScript to properly create our live video stream using our webcam as input\n",
        "def video_stream():\n",
        "  js = Javascript('''\n",
        "    var video;\n",
        "    var div = null;\n",
        "    var stream;\n",
        "    var captureCanvas;\n",
        "    var imgElement;\n",
        "    var labelElement;\n",
        "    \n",
        "    var pendingResolve = null;\n",
        "    var shutdown = false;\n",
        "    \n",
        "    function removeDom() {\n",
        "       stream.getVideoTracks()[0].stop();\n",
        "       video.remove();\n",
        "       div.remove();\n",
        "       video = null;\n",
        "       div = null;\n",
        "       stream = null;\n",
        "       imgElement = null;\n",
        "       captureCanvas = null;\n",
        "       labelElement = null;\n",
        "    }\n",
        "    \n",
        "    function onAnimationFrame() {\n",
        "      if (!shutdown) {\n",
        "        window.requestAnimationFrame(onAnimationFrame);\n",
        "      }\n",
        "      if (pendingResolve) {\n",
        "        var result = \"\";\n",
        "        if (!shutdown) {\n",
        "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
        "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
        "        }\n",
        "        var lp = pendingResolve;\n",
        "        pendingResolve = null;\n",
        "        lp(result);\n",
        "      }\n",
        "    }\n",
        "    \n",
        "    async function createDom() {\n",
        "      if (div !== null) {\n",
        "        return stream;\n",
        "      }\n",
        "\n",
        "      div = document.createElement('div');\n",
        "      div.style.border = '2px solid black';\n",
        "      div.style.padding = '3px';\n",
        "      div.style.width = '100%';\n",
        "      div.style.maxWidth = '600px';\n",
        "      document.body.appendChild(div);\n",
        "      \n",
        "      const modelOut = document.createElement('div');\n",
        "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
        "      labelElement = document.createElement('span');\n",
        "      labelElement.innerText = 'No data';\n",
        "      labelElement.style.fontWeight = 'bold';\n",
        "      modelOut.appendChild(labelElement);\n",
        "      div.appendChild(modelOut);\n",
        "           \n",
        "      video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      video.width = div.clientWidth - 6;\n",
        "      video.setAttribute('playsinline', '');\n",
        "      video.onclick = () => { shutdown = true; };\n",
        "      stream = await navigator.mediaDevices.getUserMedia(\n",
        "          {video: { facingMode: \"environment\"}});\n",
        "      div.appendChild(video);\n",
        "\n",
        "      imgElement = document.createElement('img');\n",
        "      imgElement.style.position = 'absolute';\n",
        "      imgElement.style.zIndex = 1;\n",
        "      imgElement.onclick = () => { shutdown = true; };\n",
        "      div.appendChild(imgElement);\n",
        "      \n",
        "      const instruction = document.createElement('div');\n",
        "      instruction.innerHTML = \n",
        "          '<span style=\"color: red; font-weight: bold;\">' +\n",
        "          'When finished, click here or on the video to stop this demo</span>';\n",
        "      div.appendChild(instruction);\n",
        "      instruction.onclick = () => { shutdown = true; };\n",
        "      \n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      captureCanvas = document.createElement('canvas');\n",
        "      captureCanvas.width = 640; //video.videoWidth;\n",
        "      captureCanvas.height = 480; //video.videoHeight;\n",
        "      window.requestAnimationFrame(onAnimationFrame);\n",
        "      \n",
        "      return stream;\n",
        "    }\n",
        "    async function stream_frame(label, imgData) {\n",
        "      if (shutdown) {\n",
        "        removeDom();\n",
        "        shutdown = false;\n",
        "        return '';\n",
        "      }\n",
        "\n",
        "      var preCreate = Date.now();\n",
        "      stream = await createDom();\n",
        "      \n",
        "      var preShow = Date.now();\n",
        "      if (label != \"\") {\n",
        "        labelElement.innerHTML = label;\n",
        "      }\n",
        "            \n",
        "      if (imgData != \"\") {\n",
        "        var videoRect = video.getClientRects()[0];\n",
        "        imgElement.style.top = videoRect.top + \"px\";\n",
        "        imgElement.style.left = videoRect.left + \"px\";\n",
        "        imgElement.style.width = videoRect.width + \"px\";\n",
        "        imgElement.style.height = videoRect.height + \"px\";\n",
        "        imgElement.src = imgData;\n",
        "      }\n",
        "      \n",
        "      var preCapture = Date.now();\n",
        "      var result = await new Promise(function(resolve, reject) {\n",
        "        pendingResolve = resolve;\n",
        "      });\n",
        "      shutdown = false;\n",
        "      \n",
        "      return {'create': preShow - preCreate, \n",
        "              'show': preCapture - preShow, \n",
        "              'capture': Date.now() - preCapture,\n",
        "              'img': result};\n",
        "    }\n",
        "    ''')\n",
        "\n",
        "  display(js)\n",
        "  \n",
        "\n",
        "def video_frame(label, bbox):\n",
        "  data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n",
        "  return data\n",
        "# start streaming video from webcam\n",
        "\n",
        "\n",
        "video_stream()\n",
        "# label for video\n",
        "label_html = 'Capturing...'\n",
        "# initialze bounding box to empty\n",
        "bbox = ''\n",
        "count = 0 \n",
        "i=0\n",
        "labels = [\"angry\",\"disgust\",\"fear\",\"happy\",\"neutral\",\"sad\",\"surprise\"]\n",
        "while True:\n",
        "    js_reply = video_frame(label_html, bbox)\n",
        "    if not js_reply:\n",
        "        break\n",
        "\n",
        "    # convert JS response to OpenCV Image\n",
        "    img = js_to_image(js_reply[\"img\"])\n",
        "    img = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
        "    # create transparent overlay for bounding box\n",
        "    bbox_array = np.zeros([480,640,4], dtype=np.uint8)\n",
        "    # get face region coordinates\n",
        "    faces = face_cascade.detectMultiScale(img)\n",
        "    # get face bounding box for overlay\n",
        "    for (x,y,w,h) in faces:\n",
        "        cv2.rectangle(bbox_array,(x,y),(x+w,y+h),(255,0,0),3)\n",
        "        roi_gray = img[y:y+w,x:x+h]\n",
        "        roi_gray = cv2.resize(roi_gray,(48,48),interpolation=cv2.INTER_AREA)\n",
        "        if np.sum([roi_gray])!=0:\n",
        "            img_px = img_to_array(roi_gray)\n",
        "            img_px = np.expand_dims(img_px,axis=0)\n",
        "            pred = model.predict(img_px)\n",
        "            max_in = np.argmax(pred[0])\n",
        "            label = labels[max_in]\n",
        "            label_pos = (x,y-10)\n",
        "            cv2.putText(bbox_array,label,label_pos,cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),2)\n",
        "            folder = \"\"\n",
        "            if max_in == 0:\n",
        "                folder = \"angry\"\n",
        "                cv2.imwrite(\"res/\"+folder+\"/myImg\"+str(i)+\".jpg\",img)\n",
        "            elif max_in == 2:\n",
        "                folder = \"fear\"\n",
        "                cv2.imwrite(\"res/\"+folder+\"/myImg\"+str(i)+\".jpg\",img)\n",
        "            elif max_in == 4:\n",
        "                folder = \"neutral\"\n",
        "                cv2.imwrite(\"res/\"+folder+\"/myImg\"+str(i)+\".jpg\",img)\n",
        "            i = i+1\n",
        "    bbox_array[:,:,3] = (bbox_array.max(axis = 2) > 0 ).astype(int) * 255\n",
        "    # convert overlay of bbox into bytes\n",
        "    bbox_bytes = bbox_to_bytes(bbox_array)\n",
        "    # update bbox so next frame gets new overlay\n",
        "    bbox = bbox_bytes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    var video;\n",
              "    var div = null;\n",
              "    var stream;\n",
              "    var captureCanvas;\n",
              "    var imgElement;\n",
              "    var labelElement;\n",
              "    \n",
              "    var pendingResolve = null;\n",
              "    var shutdown = false;\n",
              "    \n",
              "    function removeDom() {\n",
              "       stream.getVideoTracks()[0].stop();\n",
              "       video.remove();\n",
              "       div.remove();\n",
              "       video = null;\n",
              "       div = null;\n",
              "       stream = null;\n",
              "       imgElement = null;\n",
              "       captureCanvas = null;\n",
              "       labelElement = null;\n",
              "    }\n",
              "    \n",
              "    function onAnimationFrame() {\n",
              "      if (!shutdown) {\n",
              "        window.requestAnimationFrame(onAnimationFrame);\n",
              "      }\n",
              "      if (pendingResolve) {\n",
              "        var result = \"\";\n",
              "        if (!shutdown) {\n",
              "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
              "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
              "        }\n",
              "        var lp = pendingResolve;\n",
              "        pendingResolve = null;\n",
              "        lp(result);\n",
              "      }\n",
              "    }\n",
              "    \n",
              "    async function createDom() {\n",
              "      if (div !== null) {\n",
              "        return stream;\n",
              "      }\n",
              "\n",
              "      div = document.createElement('div');\n",
              "      div.style.border = '2px solid black';\n",
              "      div.style.padding = '3px';\n",
              "      div.style.width = '100%';\n",
              "      div.style.maxWidth = '600px';\n",
              "      document.body.appendChild(div);\n",
              "      \n",
              "      const modelOut = document.createElement('div');\n",
              "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
              "      labelElement = document.createElement('span');\n",
              "      labelElement.innerText = 'No data';\n",
              "      labelElement.style.fontWeight = 'bold';\n",
              "      modelOut.appendChild(labelElement);\n",
              "      div.appendChild(modelOut);\n",
              "           \n",
              "      video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      video.width = div.clientWidth - 6;\n",
              "      video.setAttribute('playsinline', '');\n",
              "      video.onclick = () => { shutdown = true; };\n",
              "      stream = await navigator.mediaDevices.getUserMedia(\n",
              "          {video: { facingMode: \"environment\"}});\n",
              "      div.appendChild(video);\n",
              "\n",
              "      imgElement = document.createElement('img');\n",
              "      imgElement.style.position = 'absolute';\n",
              "      imgElement.style.zIndex = 1;\n",
              "      imgElement.onclick = () => { shutdown = true; };\n",
              "      div.appendChild(imgElement);\n",
              "      \n",
              "      const instruction = document.createElement('div');\n",
              "      instruction.innerHTML = \n",
              "          '<span style=\"color: red; font-weight: bold;\">' +\n",
              "          'When finished, click here or on the video to stop this demo</span>';\n",
              "      div.appendChild(instruction);\n",
              "      instruction.onclick = () => { shutdown = true; };\n",
              "      \n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      captureCanvas = document.createElement('canvas');\n",
              "      captureCanvas.width = 640; //video.videoWidth;\n",
              "      captureCanvas.height = 480; //video.videoHeight;\n",
              "      window.requestAnimationFrame(onAnimationFrame);\n",
              "      \n",
              "      return stream;\n",
              "    }\n",
              "    async function stream_frame(label, imgData) {\n",
              "      if (shutdown) {\n",
              "        removeDom();\n",
              "        shutdown = false;\n",
              "        return '';\n",
              "      }\n",
              "\n",
              "      var preCreate = Date.now();\n",
              "      stream = await createDom();\n",
              "      \n",
              "      var preShow = Date.now();\n",
              "      if (label != \"\") {\n",
              "        labelElement.innerHTML = label;\n",
              "      }\n",
              "            \n",
              "      if (imgData != \"\") {\n",
              "        var videoRect = video.getClientRects()[0];\n",
              "        imgElement.style.top = videoRect.top + \"px\";\n",
              "        imgElement.style.left = videoRect.left + \"px\";\n",
              "        imgElement.style.width = videoRect.width + \"px\";\n",
              "        imgElement.style.height = videoRect.height + \"px\";\n",
              "        imgElement.src = imgData;\n",
              "      }\n",
              "      \n",
              "      var preCapture = Date.now();\n",
              "      var result = await new Promise(function(resolve, reject) {\n",
              "        pendingResolve = resolve;\n",
              "      });\n",
              "      shutdown = false;\n",
              "      \n",
              "      return {'create': preShow - preCreate, \n",
              "              'show': preCapture - preShow, \n",
              "              'capture': Date.now() - preCapture,\n",
              "              'img': result};\n",
              "    }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4sqpPgXIuRR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}